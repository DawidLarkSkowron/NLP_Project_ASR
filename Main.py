import whisper
import torch
import os
import json
import srt
import streamlit as st
import tempfile
import language_tool_python
import requests
import difflib
from datetime import timedelta
from subprocess import run, CalledProcessError, DEVNULL
from emotion_detection import EmotionDetector

# === Pobieranie sÅ‚ownikÃ³w ===
def download_if_needed(url, path):
    if not os.path.exists(path):
        r = requests.get(url)
        if r.status_code == 200:
            with open(path, 'wb') as f:
                f.write(r.content)
        else:
            raise Exception(f"Nie udaÅ‚o siÄ™ pobraÄ‡ pliku: {url}")

# === Inicjalizacja LanguageTool ===
def get_language_tool(lang_code):
    try:
        tool = language_tool_python.LanguageTool(lang_code)
        return tool
    except Exception as e:
        st.error(f"âŒ BÅ‚Ä…d inicjalizacji LanguageTool ({lang_code}): {e}")
        return None

# === Korekta pisowni tekstu ===
def correct_spelling(text, tool):
    if not tool:
        return text
    
    matches = tool.check(text)
    corrected_text = language_tool_python.utils.correct(text, matches)
    return corrected_text

# === Korekta pisowni segmentÃ³w (dla SRT) ===
def correct_segments(segments, tool):
    if not tool:
        return segments
        
    corrected_segments = []
    for segment in segments:
        original = segment["text"]
        segment["text"] = correct_spelling(original, tool)
        corrected_segments.append(segment)
    return corrected_segments

# === RÃ³Å¼nice tekstu ===
def show_diff(original, corrected):
    diff = difflib.ndiff(original.split(), corrected.split())
    return " ".join(
        [f"**{w[2:]}**" if w.startswith("+ ") else w[2:] for w in diff if not w.startswith("- ")]
    )

# === Transkrypcja audio ===
def transcribe_audio(audio_path, model_size="large-v3", language=None):
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"File {audio_path} not found.")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = whisper.load_model(model_size, device=device)

    progress_bar = st.progress(0)
    audio = whisper.load_audio(audio_path)
    duration = len(audio) / whisper.audio.SAMPLE_RATE
    segment_duration = 30
    segments = [(i, min(i + segment_duration, duration))
                for i in range(0, int(duration), segment_duration)]

    results = []
    for i, (start, end) in enumerate(segments):
        segment_audio = audio[int(start * whisper.audio.SAMPLE_RATE):int(end * whisper.audio.SAMPLE_RATE)]
        result = model.transcribe(segment_audio, language=language)
        results.append(result)
        progress_bar.progress((i + 1) / len(segments))

    combined_result = {
        "text": " ".join([result["text"] for result in results]),
        "segments": [segment for result in results for segment in result.get("segments", [])]
    }

    progress_bar.empty()
    return combined_result

# === Zapis transkrypcji ===
def save_transcription(text, segments):
    subtitles = []
    for i, segment in enumerate(segments):
        start = timedelta(seconds=segment["start"])
        end = timedelta(seconds=segment["end"])
        subtitles.append(srt.Subtitle(index=i+1, start=start, end=end, content=segment["text"]))

    return text, srt.compose(subtitles), json.dumps({
        "text": text,
        "segments": segments
    }, indent=4, ensure_ascii=False)

# === Sprawdzenie ffmpeg ===
def check_ffmpeg():
    try:
        run(["ffmpeg", "-version"], stdout=DEVNULL, stderr=DEVNULL, check=True)
    except CalledProcessError:
        st.error("âš ï¸ FFmpeg nie jest zainstalowany lub nie jest w PATH. Zainstaluj FFmpeg i sprÃ³buj ponownie.")
        return False
    return True

# === UI ===
st.set_page_config(page_title="Transkrypcja Audio", page_icon="ğŸ™ï¸", layout="wide")
st.title("ğŸ™ï¸ Transkrypcja Audio")
st.markdown("**Konwertuj swoje nagrania audio na tekst za pomocÄ… modelu Whisper i sprawdÅº pisowniÄ™!**")

if not check_ffmpeg():
    st.stop()

languages = {
    "Angielski": "en", "Polski": "pl"
}

language_choice = st.selectbox("ğŸŒ Wybierz jÄ™zyk transkrypcji:", list(languages.keys()), index=0)
selected_language = languages[language_choice]

uploaded_file = st.file_uploader("ğŸ“¤ Wgraj plik audio", type=["mp3", "wav", "m4a", "ogg"])

if uploaded_file is not None:
    # Zapisz Å›cieÅ¼kÄ™ do tymczasowego pliku w sesji
    if 'temp_audio_path' not in st.session_state:
        temp_path = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[-1]).name
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.read())
        st.session_state.temp_audio_path = temp_path
        
        # Wykonaj transkrypcjÄ™
        with st.spinner("â³ Przetwarzanie pliku..."):
            result = transcribe_audio(temp_path, language=selected_language)
            st.session_state.transcription_raw = result
            
    else:
        result = st.session_state.transcription_raw
    
    original_text = result["text"]
    segments = result["segments"]
    
    # WyÅ›wietl wyniki transkrypcji
    # WyÅ›wietl wyniki transkrypcji
    st.success("âœ… Transkrypcja zakoÅ„czona!")
    st.subheader("ğŸ“„ Oryginalna transkrypcja:")
    st.text_area("Oryginalny tekst", original_text, height=250, key="original_text")
    
    # Formularz do korekty pisowni
    with st.form("spelling_correction_form"):
        corrected_text = original_text
        corrected_segments = segments
        
        if selected_language in ["pl", "en"]:
            if st.form_submit_button("ğŸª„ Popraw pisowniÄ™ (Hunspell)"):
                tool = get_language_tool(selected_language)
                if tool:
                    with st.spinner("ğŸ” Sprawdzanie pisowni..."):
                        corrected_segments = correct_segments(segments.copy(), tool)
                        corrected_text = correct_spelling(original_text, tool)
                        diff = show_diff(original_text, corrected_text)

                        st.subheader("âœ… Po korekcie:")
                        st.text_area("Tekst po korekcie", corrected_text, height=250, key="corrected_text")
                        st.subheader("ğŸ§¾ RÃ³Å¼nice:")
                        st.markdown(diff)

    # Formularz do wykrywania emocji
    with st.form("emotion_detection_form"):
        if st.form_submit_button("ğŸ§  Wykryj emocje"):
            with st.spinner("ğŸ” Wykrywanie emocji..."):
                # Przekazujemy wybrany jÄ™zyk do detektora emocji
                language_code = selected_language if selected_language else "en"
                detector = EmotionDetector(language=language_code)
                emotion_results = detector.process_transcription({"text": corrected_text, "segments": corrected_segments})
                if emotion_results:
                    st.subheader("ğŸ§  Emocje wykryte w transkrypcji:")
                    
                    # Definiuj emotki dla rÃ³Å¼nych emocji
                    emotion_emojis = {
                        "happiness": "ğŸ˜„",  # uÅ›miech
                        "sadness": "ğŸ˜¢",    # pÅ‚acz
                        "anger": "ğŸ˜¡",      # zÅ‚oÅ›Ä‡
                        "fear": "ğŸ˜¨",       # strach
                        "surprise": "ğŸ˜®",    # zaskoczenie
                        "neutral": "ğŸ˜",     # neutralna
                        "disgust": "ğŸ¤¢",     # obrzydzenie
                        "joy": "ğŸ˜ƒ",         # radoÅ›Ä‡
                        "love": "ğŸ˜",       # miÅ‚oÅ›Ä‡
                        "admiration": "ğŸ˜Š", # podziw
                        "amusement": "ğŸ˜‚",  # rozbawienie
                        "annoyance": "ğŸ˜’",  # irytacja
                        "approval": "ğŸ‘",    # aprobata
                        "caring": "ğŸ¤—",      # troska
                        "confusion": "ğŸ¤”",   # zmieszanie
                        "curiosity": "ğŸ¤“",   # ciekawoÅ›Ä‡
                        "desire": "ğŸ˜",      # poÅ¼Ä…danie
                        "disappointment": "ğŸ˜", # rozczarowanie
                        "disapproval": "ğŸ‘", # dezaprobata
                        "embarrassment": "ğŸ˜³", # zawstydzenie
                        "excitement": "ğŸ˜",  # ekscytacja
                        "gratitude": "ğŸ™",   # wdziÄ™cznoÅ›Ä‡
                        "grief": "ğŸ˜”",      # Å¼al
                        "nervousness": "ğŸ˜¬", # zdenerwowanie
                        "optimism": "ğŸ™‚",    # optymizm
                        "pride": "ğŸ¤©",       # duma
                        "realization": "ğŸ˜¯", # uÅ›wiadomienie
                        "relief": "ğŸ˜Œ",      # ulga
                        "remorse": "ğŸ˜•",     # wyrzuty sumienia
                    }
                    
                    # Grupuj wyniki wedÅ‚ug emocji
                    emotions_grouped = {}
                    for result in emotion_results:
                        emotion_label = result['emotion']['label']
                        if emotion_label not in emotions_grouped:
                            emotions_grouped[emotion_label] = []
                        emotions_grouped[emotion_label].append(result)
                    
                    # WyÅ›wietl pogrupowane emocje
                    for emotion, results in emotions_grouped.items():
                        emoji = emotion_emojis.get(emotion.lower(), "ğŸ˜¶")  # DomyÅ›lna emotka jeÅ›li nie znaleziono
                        avg_score = sum(r['emotion']['score'] for r in results) / len(results)
                        
                        # NagÅ‚Ã³wek dla emocji
                        st.markdown(f"### {emoji} **{emotion}** (pewnoÅ›Ä‡: {avg_score:.2f})")
                        
                        # Fragment tekstu dla tej emocji
                        st.markdown("#### Fragmenty:")
                        for i, result in enumerate(results, 1):
                            start_time = result.get('start', 0)
                            end_time = result.get('end', 0)
                            text = result.get('text', 'Brak tekstu')
                            st.markdown(f"**{i}.** *{start_time:.1f}s - {end_time:.1f}s:* \"{text}\"")
                        
                        st.markdown("---")
                    
                    # Zapisz wyniki emocji do sesji
                    st.session_state.emotion_results = emotion_results

    # Przyciski do pobierania plikÃ³w
    col1, col2, col3 = st.columns(3)
    
    text_output, srt_output, json_output = save_transcription(corrected_text, corrected_segments)
    
    if st.session_state.get('emotion_results'):
        emotion_json = json.dumps(st.session_state.emotion_results, indent=4, ensure_ascii=False)
        col1.download_button("ğŸ“¥ Pobierz wyniki emocji", emotion_json, "emotion_results.json", "application/json", key="download_emotions")
    
    col2.download_button("ğŸ“¥ Pobierz TXT", text_output, "transcription.txt", "text/plain", key="download_txt")
    col3.download_button("ğŸ“¥ Pobierz SRT", srt_output, "transcription.srt", "text/plain", key="download_srt")
    st.download_button("ğŸ“¥ Pobierz JSON", json_output, "transcription.json", "application/json", key="download_json")
